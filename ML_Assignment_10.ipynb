{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment_10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSCcgWGefI0IsmK5SJuhmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/97-63/Sabudh_Foundation_projects/blob/master/ML_Assignment_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiJDp3v_la7R",
        "colab_type": "code",
        "outputId": "4b8cf8b8-27d8-4c6a-e892-8735b6705697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Problem Statement 1\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "#from sklearn import preprocessing, cross_validation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(106)\n",
        "\n",
        "\n",
        "for i in range(250):\n",
        "    walkrand = [0]\n",
        "    for x in range(100):\n",
        "        step = walkrand[-1]\n",
        "        dice = np.random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + np.random.randint(1,7)\n",
        "        \n",
        "    print(step)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "4\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n",
            "0\n",
            "5\n",
            "3\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "5\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "3\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "5\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "6\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "5\n",
            "1\n",
            "3\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "6\n",
            "0\n",
            "0\n",
            "5\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "6\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "5\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "4\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "5\n",
            "2\n",
            "1\n",
            "4\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "6\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm6ekZ7Gmhrl",
        "colab_type": "code",
        "outputId": "8d532d78-0bc7-4dc0-bf47-d84ed053f179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "#Problem statement 2\n",
        "\n",
        "#Random data for multiple linear regression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.4 * X[0]) + eps + (0.5 * X[1]) + (0.3 * X[2]) + (0.4 * X[3])\n",
        "data_kir = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "df = pd.DataFrame(data_kir)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3         Y\n",
            "0 -0.078286  1.382687 -0.456362 -1.178895  1.222870\n",
            "1 -0.321537 -0.812534 -0.048542  1.749520  1.319171\n",
            "2  0.683298 -0.525235  1.718341 -0.992099  1.200755\n",
            "3 -0.255383  0.410224 -0.612685  2.234023  1.951680\n",
            "4 -2.658708 -0.359718  0.577471  0.320805  0.055308\n",
            "          X0        X1        X2        X3         Y\n",
            "95  2.547630  0.998754  0.447265 -1.183157  2.077941\n",
            "96 -0.876331 -1.174897  0.742662 -0.433924  0.309762\n",
            "97  1.081222 -2.389929  1.257862  0.289980  1.167874\n",
            "98 -1.677698  0.564100  0.845884 -0.146694  1.018677\n",
            "99 -1.813409  0.970988  1.185309 -0.660920  1.153760\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.097538    0.043344   -0.065210   -0.013928    1.067182\n",
            "std      1.048669    1.061778    1.020303    0.970942    0.827667\n",
            "min     -2.658708   -2.389929   -2.773569   -2.329947   -1.025739\n",
            "25%     -0.548884   -0.732658   -0.837643   -0.701315    0.490037\n",
            "50%      0.117075    0.102703    0.045763   -0.139317    1.111851\n",
            "75%      0.797131    0.786604    0.699974    0.546306    1.619028\n",
            "max      2.547630    2.470974    2.240926    2.472993    3.094520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhgDAfJjm3rw",
        "colab_type": "code",
        "outputId": "2de09fe9-075d-4f56-92b4-8a8fcd113351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "#Random data for logistic regression\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_kir = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_kir)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "print(df1.info())\n",
        "print(df1.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3  Y\n",
            "0  0.259584 -0.061161  0.173691  0.552378  1\n",
            "1 -1.062082  0.907542 -0.510146  1.693099  1\n",
            "2 -1.156974  0.986781 -1.099892 -0.654495  1\n",
            "3 -0.657931  0.159428 -1.536288  3.648258  1\n",
            "4 -1.095864 -0.168840  0.715476  0.340386  1\n",
            "          X0        X1        X2        X3  Y\n",
            "95 -1.064228  1.568575 -0.759363  0.270406  1\n",
            "96  0.548421 -0.280565 -0.343741 -0.498473  1\n",
            "97  0.885384  1.790532  0.774852  0.379414  1\n",
            "98 -0.871798  1.538736 -1.618403  0.206618  1\n",
            "99 -0.001934 -0.870512  0.245849  0.433834  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   Y       100 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.0 KB\n",
            "None\n",
            "               X0          X1          X2          X3           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.065772    0.020196   -0.037156    0.192675    0.910000\n",
            "std      1.092442    1.024796    0.931603    0.998779    0.287623\n",
            "min     -2.655168   -3.225857   -2.586105   -1.861237    0.000000\n",
            "25%     -0.892124   -0.623729   -0.602300   -0.500514    1.000000\n",
            "50%     -0.065149   -0.026609   -0.123483    0.155059    1.000000\n",
            "75%      0.754918    0.773700    0.455741    0.711815    1.000000\n",
            "max      2.715799    2.164482    2.724651    3.686792    1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8MqKzpInN7A",
        "colab_type": "code",
        "outputId": "0b262511-8ad8-41a6-ee1e-e096f0ce8380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "\n",
        "#Random data for K means clustering\n",
        "\n",
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kir = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kir)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "print(df3.info())\n",
        "print(df3.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -0.510308 -1.795618\n",
            "1 -0.625926 -0.452778\n",
            "2 -0.599589 -0.752278\n",
            "3 -0.499208 -0.172139\n",
            "4 -0.792804 -1.307034\n",
            "          X0        X1\n",
            "95  1.917793  2.272455\n",
            "96  1.740722  1.598209\n",
            "97  2.716915  1.752051\n",
            "98  1.202330  2.311930\n",
            "99  1.190269  1.739195\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.7 KB\n",
            "None\n",
            "               X0          X1\n",
            "count  100.000000  100.000000\n",
            "mean     0.507872    0.483491\n",
            "std      1.569509    1.613336\n",
            "min     -1.984807   -1.915076\n",
            "25%     -0.817992   -1.046081\n",
            "50%      0.450227    0.506441\n",
            "75%      1.897389    2.026631\n",
            "max      2.967106    2.906957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJt-6OiRnYqy",
        "colab_type": "code",
        "outputId": "1d599f58-6c18-4a2d-ea83-cd15e4e90fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Problem statement - 3\n",
        "#Linear Regression using gradient descent\n",
        "\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07022391201632956 0.19295808918226112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHY8ga25nmD3",
        "colab_type": "code",
        "outputId": "ca053202-6a2e-4a12-c271-f103dec085a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "#Logistic regression using Gradient descent\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.30218698202575234\n",
            "0.30184272713509336\n",
            "0.3015050428731425\n",
            "0.30117391389223924\n",
            "0.30084932356652183\n",
            "0.3005312536389595\n",
            "0.3002196838776274\n",
            "0.299914591744611\n",
            "0.29961595208099046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2zuD1Lan1O9",
        "colab_type": "code",
        "outputId": "5cabd295-8fe3-445d-d207-2fdb72ea0cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Linear Regreesion using L1 Regularization\n",
        "X = df.iloc[:,0].values\n",
        "\n",
        "y = df.iloc[:,4].values\n",
        "a1 = 0\n",
        "a0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = a1*X + a0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * a1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  a1 = a1 - (l*d1)\n",
        "  a0 = a0 - (l*d0)\n",
        "\n",
        "print(a1,a0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06123660190376337 0.19304237633720064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZPiECiyoVw_",
        "colab_type": "code",
        "outputId": "6cd87ac4-c699-4887-833c-1c73b28719c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "# Linear Regreesion using L2 Regularization\n",
        "X = df.iloc[:,0].values\n",
        "\n",
        "y = df.iloc[:,4].values\n",
        "a1 = 0\n",
        "a0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = a1*X + a0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * a1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *a1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  a1 = a1 - (l*d1)\n",
        "  a0 = a0 - (l*d0)\n",
        "\n",
        "print(a1,a0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06988668697790323 0.1929602233408087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgACOEtZor8Q",
        "colab_type": "code",
        "outputId": "baf66f63-7bb5-4acb-a201-8f32974afb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "# Logistic regression using L1 regualrization\n",
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.09603118010153994\n",
            "-0.491780672928797\n",
            "-0.8844921163799819\n",
            "-1.2742000530375965\n",
            "-1.6609388473783382\n",
            "-2.044742673505467\n",
            "-2.4256455057649258\n",
            "-2.803681111778892\n",
            "-3.178883047453161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAEL27hwo0Ph",
        "colab_type": "code",
        "outputId": "26932a06-7dd4-41c7-8216-206f856db89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "# Logistic regression using L2 regualrization\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.3025361324209029\n",
            "0.30321248839441206\n",
            "0.3045277242946211\n",
            "0.30644399896440966\n",
            "0.3089247888559124\n",
            "0.31193486015314187\n",
            "0.31544024271149673\n",
            "0.31940820553006727\n",
            "0.32380723348189916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj0oiMtSpELf",
        "colab_type": "code",
        "outputId": "570b237b-b3a0-44b8-9cd4-b6b039af0bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# K Means Clustering Algorithm\n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]\n",
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.92713460193312\n",
            "186.35662084088918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwrlfzjYpP4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Problem Statement - 4\n",
        "\n",
        "# Linear Regression from scratch using OOPS\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4zG1GaQpis4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Logistic Regression from scratch using OOPS\n",
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_4ndypWppYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#K Means from scratch using OOPS\n",
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}